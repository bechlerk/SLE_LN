{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and Load Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from pandas import read_csv\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import kaplanmeier as km\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from qqman import qqman\n",
    "import pandas as pd\n",
    "from pandas_plink import read_plink\n",
    "from scipy.stats import ttest_ind\n",
    "import math\n",
    "import os\n",
    "from lifelines import KaplanMeierFitter\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import preprocessing\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from xgboost import XGBClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create exposure cohort in Big Query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'kbechler'\n",
    "nero_gcp_project = 'som-nero-nigam-starr'\n",
    "cdm_project_id = 'som-nero-nigam-starr'\n",
    "cdm_dataset_id = 'starr_omop_cdm5_deid_20211213'\n",
    "work_project_id = 'som-nero-nigam-starr'\n",
    "work_dataset_id = f'{user_id}_explore'\n",
    "cdm_subset_dataset_id = 'cdm_subset'\n",
    "cohort_table_id = 'exp_cohort'\n",
    "cohort_id = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kbechler/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use correct path whether you are local or Nero\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/kbechler/adc.json' \n",
    "\n",
    "# Set correct Nero project\n",
    "os.environ['GCLOUD_PROJECT'] = nero_gcp_project\n",
    "client = bigquery.Client(project = work_project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create working dataset within the user's NERO project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_dataset(f\"{work_project_id}.{work_dataset_id}\", exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to visualize un-formatted notes in a slightly-better way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_note(note_text):\n",
    "    my_wrap = textwrap.TextWrapper(width = 80)\n",
    "    [print(line) for line in my_wrap.wrap(text=note_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read file with SQL code from cohort derived from ATLAS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohort 1402 from ATLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrized_sql = open('exp_cohort_dec21.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parametrized_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute each one of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = re.sub(pattern=r'@temp_database_schema', \n",
    "             repl=f\"`{work_project_id}.{work_dataset_id}`\",\n",
    "             string=parametrized_sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@target_database_schema', \n",
    "             repl=f\"`{work_project_id}.{work_dataset_id}`\",\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@target_cohort_table', \n",
    "             repl=cohort_table_id,\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@target_cohort_id', \n",
    "             repl=f\"{cohort_id}\",\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@vocabulary_database_schema', \n",
    "             repl=f\"`{cdm_project_id}.{cdm_dataset_id}`\",\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@cdm_database_schema', \n",
    "             repl=f\"`{cdm_project_id}.{cdm_dataset_id}`\",\n",
    "             string=sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = sql.lower()\n",
    "sql = re.sub(pattern=r'create table', \n",
    "             repl=\"create or replace table\",\n",
    "             string=sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohort table MUST exist before executing this for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2 = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "`{work_project_id}.{work_dataset_id}.{cohort_table_id}`\n",
    "(\n",
    "cohort_definition_id INT64,\n",
    "subject_id INT64,\n",
    "cohort_start_date DATE,\n",
    "cohort_end_date DATE\n",
    ")\n",
    "\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'cohort_table_id': cohort_table_id})\n",
    "\n",
    "client.query(sql2).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execute SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "client.query(sql).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Subset CDM using the cohort table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset condition occurrence table to filter criteria based on notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    CREATE OR REPLACE TABLE\n",
    "     `{work_project_id}.{cdm_subset_dataset_id}.{table_id}` AS\n",
    "    SELECT\n",
    "     c.concept_name as _{concept_id_prefix}_name,\n",
    "     table_.*\n",
    "    FROM\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.{table_id}` table_\n",
    "    JOIN\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.concept` c\n",
    "    ON\n",
    "     c.concept_id = table_.{concept_id_prefix}_concept_id\n",
    "    JOIN\n",
    "     `{work_project_id}.{work_dataset_id}.{cohort_table_id}` cohort\n",
    "    ON\n",
    "     table_.person_id = cohort.subject_id\n",
    "    WHERE\n",
    "     cohort_definition_id = {cohort_id}\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'work_dataset_id': work_dataset_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'cdm_project_id': cdm_project_id,\n",
    "                    'cdm_dataset_id': cdm_dataset_id,\n",
    "                    'cohort_table_id': cohort_table_id,\n",
    "                    'cohort_id': cohort_id,\n",
    "                    'table_id': 'condition_occurrence',\n",
    "                    'concept_id_prefix': 'condition'})\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from som-nero-nigam-starr.cdm_subset.condition_occurrence\"\n",
    "condition_df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from som-nero-nigam-starr.kbechler_explore.exp_cohort\"\n",
    "cohort_df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique patients in cohort df: \", cohort_df.subject_id.nunique())\n",
    "print(\"Number of unique patients in condition df: \",condition_df.person_id.nunique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(condition_df.condition_concept_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Condition codes: SLE\n",
    "4055640: Lung disease with systemic lupus erythematosus  \n",
    "4344158: Systemic lupus erythematosus with organ/system involvement  \n",
    "4285717: SLE glomerulopehritis syndrome  \n",
    "4063581: Drug-induced systemic lupus erythematosus  \n",
    "4149913: Systemic lupus erythematosus with pericarditis  \n",
    "257628: Systemic lupus erythematosus  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Condition codes: LN\n",
    "4285717: SLE glomerulopehritis syndrome  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition concept id of SLE\n",
    "# Mapped and descendants\n",
    "sle_condition_list = [4055640, 4344158, 4285717 , 4063581, 4149913, 257628]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirms all patients have SLE condition concept id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to patients who present with SLE\n",
    "sle_condition = condition_df[condition_df['condition_concept_id'].isin(sle_condition_list)]\n",
    "sle_condition.person_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to patients who present with LN\n",
    "ln_condition = condition_df[condition_df.condition_concept_id == 4285717]\n",
    "ln_condition.person_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sle_condition._condition_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_condition._condition_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Calculate minimum date of SLE diagnosis (first instance of SLE condition id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by unique person and min condition concept ID for SLE\n",
    "sle_min = sle_condition.groupby(\"person_id\", as_index = False)['condition_start_DATETIME'].min()\n",
    "print(\"Number of unique patients:\", len(sle_min))\n",
    "sle_min.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with cohort and cohort start date to compare index date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df = pd.merge(cohort_df, sle_min, left_on = 'subject_id', right_on = 'person_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df.cohort_start_date = pd.to_datetime(cohort_df.cohort_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference between cohort start date and condition start datetime\n",
    "cohort_df['cohort_start_condition_start_dif'] = (cohort_df.cohort_start_date - cohort_df.condition_start_DATETIME).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at differences greater than -1\n",
    "cohort_df[cohort_df.cohort_start_condition_start_dif < -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to look at this handful who have cohort_start_date prior to condition_start_DATETIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Count how many of these patients have SLE in clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull note ids of these SLE patients\n",
    "# Use som-rit-phi-starr-prod for note_ids\n",
    "query = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "`{work_project_id}.{work_dataset_id}.sle_patient_notes` AS\n",
    "SELECT\n",
    "distinct(note.note_id) as note_id, \n",
    "person_id\n",
    "FROM\n",
    "`som-rit-phi-starr-prod.starr_omop_cdm5_deid_2021_12_13.note` note\n",
    "WHERE\n",
    "person_id IN\n",
    "(SELECT \n",
    "subject_id\n",
    "FROM\n",
    "`{work_project_id}.{work_dataset_id}.exp_cohort`)\n",
    "\"\"\".format_map({'cdm_project_id': cdm_project_id,\n",
    "                'cdm_dataset_id': cdm_dataset_id,\n",
    "                'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id})\n",
    "client.query(query).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull note nlps of these\n",
    "query = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "`{work_project_id}.{work_dataset_id}.sle_patient_note_nlp` AS\n",
    "SELECT\n",
    "*\n",
    "FROM\n",
    "`{cdm_project_id}.{cdm_dataset_id}.note_nlp` note_nlp\n",
    "WHERE\n",
    "note_id IN\n",
    "(SELECT\n",
    "note_id\n",
    "FROM\n",
    "`{work_project_id}.{work_dataset_id}.sle_patient_notes`)\n",
    "AND\n",
    "note_nlp.term_exists = 'Y' AND\n",
    "note_nlp.term_modifiers = '[]' AND\n",
    "note_nlp_concept_id IN\n",
    "(SELECT\n",
    "concept_id\n",
    "FROM\n",
    "`{work_project_id}.{work_dataset_id}.sle_concept_set`)\n",
    "\"\"\".format_map({'cdm_project_id': cdm_project_id,\n",
    "                'cdm_dataset_id': cdm_dataset_id,\n",
    "                'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id})\n",
    "client.query(query).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe in Jupyter Notebook\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "*\n",
    "FROM\n",
    "`{work_project_id}.{work_dataset_id}.sle_patient_note_nlp`\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id})\n",
    "\n",
    "sle_patient_note_nlp = client.query(query).to_dataframe()\n",
    "sle_patient_note_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in person_id and note_id from patient notes\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "* \n",
    "FROM \n",
    "`{work_project_id}.{work_dataset_id}.sle_patient_notes`\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id})\n",
    "\n",
    "sle_patient_note = client.query(query).to_dataframe()\n",
    "sle_patient_note.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique patients:\", sle_patient_note.person_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with note nlp \n",
    "note_merge = pd.merge(sle_patient_note_nlp, sle_patient_note, on = 'note_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique patients:\", note_merge.person_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of patients with cohort definition and mention of SLE condition concept id in clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_complete = note_merge.person_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patients_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_complete_tuple = tuple(patients_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Limit Cohort Table in ATLAS to those patients who have SLE condition present in clinical notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit cohort table\n",
    "query = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "`som-nero-nigam-starr.kbechler_explore.exp_2022` AS\n",
    "SELECT *\n",
    "FROM \n",
    "`som-nero-nigam-starr.kbechler_explore.exp_cohort` exp_cohort\n",
    "WHERE\n",
    "subject_id IN {}\"\"\".format(patients_complete_tuple)\n",
    "\n",
    "client.query(query).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table of filtered patients\n",
    "sql = \"select * from som-nero-nigam-starr.kbechler_explore.exp_2022\"\n",
    "exp_filtered_df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of patients:\", len(exp_filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Create outcome cohort from this exposure cohort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'kbechler'\n",
    "nero_gcp_project = 'som-nero-nigam-starr'\n",
    "cdm_project_id = 'som-nero-nigam-starr'\n",
    "cdm_dataset_id = 'starr_omop_cdm5_deid_20211213'\n",
    "work_project_id = 'som-nero-nigam-starr'\n",
    "work_dataset_id = f'{user_id}_explore'\n",
    "cohort_table_id = 'out_cohort'\n",
    "cohort_id = 22\n",
    "cdm_subset_dataset_id = 'cdm_subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrized_sql = open('out_dec2021.sql','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parametrized_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = re.sub(pattern=r'@temp_database_schema', \n",
    "             repl=f\"`{work_project_id}.{work_dataset_id}`\",\n",
    "             string=parametrized_sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@target_database_schema', \n",
    "             repl=f\"`{work_project_id}.{work_dataset_id}`\",\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@target_cohort_table', \n",
    "             repl=cohort_table_id,\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@target_cohort_id', \n",
    "             repl=f\"{cohort_id}\",\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@vocabulary_database_schema', \n",
    "             repl=f\"`{cdm_project_id}.{cdm_dataset_id}`\",\n",
    "             string=sql)\n",
    "\n",
    "sql = re.sub(pattern=r'@cdm_database_schema', \n",
    "             repl=f\"`{cdm_project_id}.{cdm_dataset_id}`\",\n",
    "             string=sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = sql.lower()\n",
    "sql = re.sub(pattern=r'create table', \n",
    "             repl=\"create or replace table\",\n",
    "             string=sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2 = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "`{work_project_id}.{work_dataset_id}.{cohort_table_id}`\n",
    "(\n",
    "cohort_definition_id INT64,\n",
    "subject_id INT64,\n",
    "cohort_start_date DATE,\n",
    "cohort_end_date DATE\n",
    ")\n",
    "\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'cohort_table_id': cohort_table_id})\n",
    "\n",
    "client.query(sql2).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "client.query(sql).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from som-nero-nigam-starr.kbechler_explore.out_cohort\"\n",
    "outcome_df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique patients:\", len(outcome_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with exp_filtered_df\n",
    "outcome_merged = pd.merge(outcome_df, exp_filtered_df, on = 'subject_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_merged.columns = ['out_id', 'subject_id', 'out_cohort_start_date', 'out_cohort_end_date', \n",
    "                         'exp_id', 'exp_cohort_start_date', 'exp_cohort_end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of patients from complete outcome cohort in ATLAS, then limited to the pre-filtered cohort based on \n",
    "clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_patients_tuple = tuple(outcome_merged.subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit cohort table\n",
    "query = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "`som-nero-nigam-starr.kbechler_explore.out_2022` AS\n",
    "SELECT *\n",
    "FROM \n",
    "`som-nero-nigam-starr.kbechler_explore.out_cohort` out_cohort\n",
    "WHERE\n",
    "subject_id IN {}\"\"\".format(outcome_patients_tuple)\n",
    "\n",
    "client.query(query).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table of filtered patients\n",
    "sql = \"select * from som-nero-nigam-starr.kbechler_explore.out_2022\"\n",
    "outcome_filtered_df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of patients in outcome cohort:\", len(outcome_filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create CDM subset with correct exposure cohort filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'kbechler'\n",
    "nero_gcp_project = 'som-nero-nigam-starr'\n",
    "cdm_project_id = 'som-nero-nigam-starr'\n",
    "cdm_dataset_id = 'starr_omop_cdm5_deid_20211213'\n",
    "work_project_id = 'som-nero-nigam-starr'\n",
    "work_dataset_id = 'starr_omop_cdm5_deid_20211213'\n",
    "cdm_subset_dataset_id = 'cdm_subset'\n",
    "cohort_table_id = 'exp_2022'\n",
    "cohort_id = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_dataset(f\"{work_project_id}.{cdm_subset_dataset_id}\", exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_as_is = [\n",
    "              #\"attribute_definition\", #empty\n",
    "              \"care_site\",\n",
    "              \"cdm_source\",\n",
    "              \"concept\",\n",
    "              \"concept_ancestor\",\n",
    "              \"concept_class\",\n",
    "              \"concept_relationship\",\n",
    "              \"concept_synonym\",\n",
    "              \"cost\", # empty\n",
    "              \"domain\",\n",
    "              \"drug_strength\",\n",
    "              \"metadata\",\n",
    "              \"payer_plan_period\", # empty\n",
    "              \"provider\",\n",
    "              \"relationship\",\n",
    "              \"source_to_concept_map\",\n",
    "              \"specimen\", # empty\n",
    "              \"vocabulary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for table_id in copy_as_is:\n",
    "    sql = \"\"\"\n",
    "        CREATE OR REPLACE TABLE \n",
    "         `{work_project_id}.{cdm_subset_dataset_id}.{table_id}` AS\n",
    "        SELECT * \n",
    "        FROM \n",
    "         `{cdm_project_id}.{cdm_dataset_id}.{table_id}`\n",
    "        \"\"\".format_map({'cdm_project_id': cdm_project_id,\n",
    "                        'cdm_dataset_id': cdm_dataset_id,\n",
    "                        'work_project_id': work_project_id,\n",
    "                        'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                        'table_id': table_id})\n",
    "    \n",
    "    job_config = bigquery.QueryJobConfig(dry_run=False, use_query_cache=True)\n",
    "    query_job = client.query(sql, job_config)\n",
    "    query_job.result()\n",
    "    print(\"This query will process {} bytes.\".format(query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First subset tables with an end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_with_end_date = [\"condition_occurrence\",\n",
    "                        \"device_exposure\",\n",
    "                        \"drug_exposure\",\n",
    "                        \"visit_detail\",\n",
    "                        \"visit_occurrence\"]\n",
    "\n",
    "date_column_prefix = [\"condition\",\n",
    "                      \"device_exposure\",\n",
    "                      \"drug_exposure\",\n",
    "                      \"visit_detail\",\n",
    "                      \"visit\"]\n",
    "\n",
    "concept_id_prefix = [\"condition\",\n",
    "                     \"device\",\n",
    "                     \"drug\",\n",
    "                     \"visit_detail\",\n",
    "                     \"visit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(len(tables_with_end_date)):\n",
    "    \n",
    "    table_id = tables_with_end_date[i]\n",
    "    prefix_date = date_column_prefix[i]\n",
    "    concept_id_prefix_table = concept_id_prefix[i]\n",
    "    \n",
    "    print(f'Subsetting {table_id}')\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE OR REPLACE TABLE\n",
    "     `{work_project_id}.{cdm_subset_dataset_id}.{table_id}` AS\n",
    "    SELECT \n",
    "    c.concept_name as _{concept_id_prefix}_name,\n",
    "    table_.*\n",
    "    FROM\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.{table_id}` table_\n",
    "    JOIN\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.concept` c\n",
    "    ON\n",
    "     c.concept_id = table_.{concept_id_prefix}_concept_id\n",
    "    JOIN\n",
    "     `{work_project_id}.kbechler_explore.{cohort_table_id}` cohort\n",
    "    ON\n",
    "     table_.person_id = cohort.subject_id\n",
    "    WHERE\n",
    "     cohort_definition_id = {cohort_id}\n",
    "     AND table_.{prefix_date}_start_date <= cohort.cohort_end_date\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'work_dataset_id': work_dataset_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'cdm_project_id': cdm_project_id,\n",
    "                    'cdm_dataset_id': cdm_dataset_id,\n",
    "                    'cohort_table_id': cohort_table_id,\n",
    "                    'cohort_id': cohort_id,\n",
    "                    'table_id': table_id,\n",
    "                    'prefix_date': prefix_date,\n",
    "                    'concept_id_prefix': concept_id_prefix_table})\n",
    "    \n",
    "    client.query(sql).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirror and do tables without end date but acutally have end date of cohort end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_without_end_date = [\"measurement\",\n",
    "                           #\"note_nlp\", \n",
    "                           \"observation\",\n",
    "                           \"procedure_occurrence\"]\n",
    "\n",
    "date_column_prefix = [\"measurement\",\n",
    "                      #\"note_nlp\",\n",
    "                      \"observation\",\n",
    "                      \"procedure\"]\n",
    "\n",
    "concept_id_prefix = [\"measurement\",\n",
    "                     #\"note_nlp\",\n",
    "                     \"observation\",\n",
    "                     \"procedure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables_without_end_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tables_without_end_date' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(tables_without_end_date)):\n",
    "    \n",
    "    table_id = tables_without_end_date[i]\n",
    "    prefix_date = date_column_prefix[i]\n",
    "    concept_id_prefix_table = concept_id_prefix[i]\n",
    "    \n",
    "    print(f'Subsetting {table_id}')\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE OR REPLACE TABLE\n",
    "     `{work_project_id}.{cdm_subset_dataset_id}.{table_id}` AS\n",
    "    SELECT\n",
    "    c.concept_name as _{concept_id_prefix}_name,\n",
    "    table_.*\n",
    "    FROM\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.{table_id}` table_\n",
    "    JOIN\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.concept` c\n",
    "    ON\n",
    "     c.concept_id = table_.{concept_id_prefix}_concept_id\n",
    "    JOIN\n",
    "     `{work_project_id}.{work_dataset_id}.{cohort_table_id}` cohort\n",
    "    ON\n",
    "     table_.person_id = cohort.subject_id\n",
    "    WHERE\n",
    "     cohort_definition_id = {cohort_id}\n",
    "     AND table_.{prefix_date}_date \n",
    "     <= cohort.cohort_end_date\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'work_dataset_id': work_dataset_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'cdm_project_id': cdm_project_id,\n",
    "                    'cdm_dataset_id': cdm_dataset_id,\n",
    "                    'cohort_table_id': cohort_table_id,\n",
    "                    'cohort_id': cohort_id,\n",
    "                    'table_id': table_id,\n",
    "                    'prefix_date': prefix_date,\n",
    "                    'concept_id_prefix': concept_id_prefix_table})\n",
    "    client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset note_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_without_end_date = [\"note\"]\n",
    "\n",
    "date_column_prefix = [\"note\"]\n",
    "\n",
    "concept_id_prefix = [\"note_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting note\n",
      "CPU times: user 34.8 ms, sys: 1.3 ms, total: 36.1 ms\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(tables_without_end_date)):\n",
    "    \n",
    "    table_id = tables_without_end_date[i]\n",
    "    prefix_date = date_column_prefix[i]\n",
    "    concept_id_prefix_table = concept_id_prefix[i]\n",
    "    \n",
    "    print(f'Subsetting {table_id}')\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE OR REPLACE TABLE\n",
    "     `{work_project_id}.{cdm_subset_dataset_id}.{table_id}` AS\n",
    "    SELECT\n",
    "    c.concept_name as _{concept_id_prefix}_name,\n",
    "    table_.*\n",
    "    FROM\n",
    "     `som-rit-phi-starr-prod.starr_omop_cdm5_deid_2021_12_13.note` table_\n",
    "    JOIN\n",
    "     `{cdm_project_id}.{cdm_dataset_id}.concept` c\n",
    "    ON\n",
    "     c.concept_id = table_.{concept_id_prefix}_concept_id\n",
    "    JOIN\n",
    "     `{work_project_id}.{work_dataset_id}.{cohort_table_id}` cohort\n",
    "    ON\n",
    "     table_.person_id = cohort.subject_id\n",
    "    WHERE\n",
    "     cohort_definition_id = {cohort_id}\n",
    "     AND table_.{prefix_date}_date \n",
    "     <= cohort.cohort_start_date\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'work_dataset_id': work_dataset_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'cdm_project_id': cdm_project_id,\n",
    "                    'cdm_dataset_id': cdm_dataset_id,\n",
    "                    'cohort_table_id': cohort_table_id,\n",
    "                    'cohort_id': cohort_id,\n",
    "                    'table_id': table_id,\n",
    "                    'prefix_date': prefix_date,\n",
    "                    'concept_id_prefix': concept_id_prefix_table})\n",
    "    client.query(sql).result();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_notes = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patient_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_patient_tuple = tuple(patient_notes.note_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'kbechler'\n",
    "nero_gcp_project = 'som-nero-nigam-starr'\n",
    "cdm_project_id = 'som-nero-nigam-starr'\n",
    "cdm_dataset_id = 'starr_omop_cdm5_deid_20211213'\n",
    "work_project_id = 'som-nero-nigam-starr'\n",
    "work_dataset_id = f'{user_id}_explore'\n",
    "cdm_subset_dataset_id = 'cdm_subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting note_nlp\n",
      "CPU times: user 35.5 ms, sys: 5.8 ms, total: 41.3 ms\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(note_nlp)):\n",
    "    \n",
    "    table_id = note_nlp[i]\n",
    "    prefix_date = date_column_prefix[i]\n",
    "    concept_id_prefix_table = concept_id_prefix[i]\n",
    "    \n",
    "    print(f'Subsetting {table_id}')\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE OR REPLACE TABLE\n",
    "     `som-nero-nigam-starr.cdm_subset.note_nlp` AS\n",
    "    SELECT\n",
    "    c.concept_name as _note_nlp_name,\n",
    "    table_.*\n",
    "    FROM\n",
    "     `som-nero-nigam-starr.starr_omop_cdm5_deid_20211213.note_nlp` table_\n",
    "    JOIN\n",
    "     `som-nero-nigam-starr.starr_omop_cdm5_deid_20211213.concept` c\n",
    "    ON\n",
    "     c.concept_id = table_.note_nlp_concept_id\n",
    "    JOIN\n",
    "         `som-nero-nigam-starr.cdm_subset.note` note\n",
    "    ON note.note_id = table_.note_id\n",
    "\"\"\"\n",
    "    client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables that we will copy by filtering only on person_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_filter_by_person_id = [\"condition_era\",\n",
    "                              \"death\",\n",
    "                              \"dose_era\",\n",
    "                              \"drug_era\",\n",
    "                              \"observation_period\",\n",
    "                              \"person\"]\n",
    "\n",
    "concept_id_prefix = [\"condition\",\n",
    "                     \"death_type\",\n",
    "                     \"drug\",\n",
    "                     \"drug\",\n",
    "                     \"period_type\",\n",
    "                     \"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(len(tables_filter_by_person_id)):\n",
    "    \n",
    "    table_id = tables_filter_by_person_id[i]\n",
    "    concept_id_prefix_table = concept_id_prefix[i]\n",
    "    \n",
    "    print(f'Subsetting {table_id}')\n",
    "    if table_id != 'location':\n",
    "        sql = \"\"\"\n",
    "        CREATE OR REPLACE TABLE\n",
    "        `{work_project_id}.{cdm_subset_dataset_id}.{table_id}` AS\n",
    "        SELECT\n",
    "        c.concept_name as _{concept_id_prefix}_name,\n",
    "        table_.*\n",
    "        FROM\n",
    "        `{cdm_project_id}.{cdm_dataset_id}.{table_id}` table_\n",
    "        JOIN\n",
    "        `{cdm_project_id}.{cdm_dataset_id}.concept` c\n",
    "        ON\n",
    "        c.concept_id = table_.{concept_id_prefix}_concept_id\n",
    "        JOIN\n",
    "        `{work_project_id}.kbechler_explore.{cohort_table_id}` cohort\n",
    "        ON\n",
    "        table_.person_id = cohort.subject_id\n",
    "        WHERE\n",
    "        cohort_definition_id = {cohort_id}\n",
    "        \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                        'work_dataset_id': work_dataset_id,\n",
    "                        'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                        'cdm_project_id': cdm_project_id,\n",
    "                        'cdm_dataset_id': cdm_dataset_id,\n",
    "                        'cohort_table_id': cohort_table_id,\n",
    "                        'cohort_id': cohort_id,\n",
    "                        'table_id': table_id,\n",
    "                        'concept_id_prefix': concept_id_prefix_table})\n",
    "\n",
    "        client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the location table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\" CREATE OR REPLACE TABLE `{work_project_id}.{cdm_subset_dataset_id}.location` AS\n",
    "        WITH t1 AS\n",
    "        (  SELECT \n",
    "            DISTINCT\n",
    "            location_id\n",
    "           FROM \n",
    "            `{work_project_id}.{cdm_subset_dataset_id}.person`\n",
    "        ),\n",
    "        t2 AS\n",
    "        (\n",
    "            SELECT\n",
    "             DISTINCT \n",
    "              location_id\n",
    "            FROM\n",
    "             `{work_project_id}.{cdm_subset_dataset_id}.care_site`\n",
    "        ),\n",
    "        t3 AS\n",
    "        (\n",
    "            SELECT\n",
    "             location_id\n",
    "            FROM\n",
    "             t1\n",
    "            UNION ALL\n",
    "            SELECT\n",
    "             location_id\n",
    "            FROM t2\n",
    "        )\n",
    "        SELECT \n",
    "         loc.*\n",
    "        FROM \n",
    "         `{cdm_project_id}.{cdm_dataset_id}.location` loc\n",
    "        WHERE\n",
    "         location_id IN (SELECT DISTINCT location_id FROM t3)\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'cdm_project_id': cdm_project_id,\n",
    "                    'cdm_dataset_id': cdm_dataset_id})\n",
    "\n",
    "\n",
    "client.query(sql).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_download = [\n",
    "                      #\"care_site\",\n",
    "                      #\"cdm_source\",\n",
    "                      #\"concept\", # Big Vocab table\n",
    "                      #\"concept_ancestor\", # Big Vocabulary Table\n",
    "                      #\"concept_class\", # Big Vocabulary Table\n",
    "                      #\"concept_relationship\", # Big Vocabulary Table\n",
    "                      #\"concept_synonym\", # Vocab Table\n",
    "                      #\"condition_era\",\n",
    "                      #\"condition_occurrence\",\n",
    "                      #\"cost\", # empty \n",
    "                      #\"death\",\n",
    "                      #\"device_exposure\",\n",
    "                      #\"domain\", # Vocab Table\n",
    "                      #\"dose_era\",\n",
    "                      #\"drug_era\",\n",
    "                      #\"drug_exposure\",\n",
    "                      #\"drug_strength\", # Vocab Table\n",
    "                      #\"fact_relationship\",                  \n",
    "                      #\"location\",\n",
    "                      #\"measurement\",\n",
    "                      #\"metadata\",\n",
    "                      #\"note\"] \n",
    "                      \"note_nlp\"] # Big Table in general\n",
    "                      #\"observation\",\n",
    "                      #\"observation_period\",\n",
    "                      #\"payer_plan_period\", # empty\n",
    "                      #\"person\",\n",
    "                      #\"procedure_occurrence\"]\n",
    "                      #\"provider\",\n",
    "                      #\"relationship\", # Vocab Table\n",
    "                      #\"source_to_concept_map\", # Vocab Table\n",
    "                      #\"specimen\", # empty\n",
    "                      #\"visit_detail\",\n",
    "                      #\"visit_occurrence\",\n",
    "                      #\"vocabulary\"] # Vocab Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbechler/.conda/envs/env_name/lib/python3.9/site-packages/google/cloud/bigquery/client.py:461: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62605193 rows for note_nlp\n"
     ]
    }
   ],
   "source": [
    "for table_id in tables_to_download:\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    SELECT \n",
    "     COUNT(*) as counts\n",
    "    FROM\n",
    "     `{work_project_id}.{cdm_subset_dataset_id}.{table_id}`\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'table_id': table_id})\n",
    "    \n",
    "    df = client.query(sql).to_dataframe()\n",
    "    \n",
    "    print(f\"{df.values[0][0]} rows for {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = \"/home/kbechler/notebooks/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading som-nero-nigam-starr.cdm_subset.note_nlp\n",
      " to file /home/kbechler/notebooks/data/note_nlp.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 42.51s: : 6query [00:42,  7.08s/query]                                                          \n",
      "Downloading: 100%|██████████| 62605193/62605193 [5:02:46<00:00, 3446.28rows/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59min 57s, sys: 1min 36s, total: 1h 1min 34s\n",
      "Wall time: 5h 39min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(tables_to_download)):\n",
    "    table_id = tables_to_download[i]\n",
    "    \n",
    "    # get the column names to ensure pandas do not do any conversion\n",
    "    table_ref = client.get_table(f'{work_project_id}.{cdm_subset_dataset_id}.{table_id}')\n",
    "    schema = {schema.name:'object' for schema in table_ref.schema}\n",
    "    \n",
    "    file_name = f\"{download_folder}/{table_id}.tsv\"\n",
    "    print(f'Downloading {work_project_id}.{cdm_subset_dataset_id}.{table_id}')\n",
    "    print(f\" to file {file_name}\")\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    SELECT\n",
    "     *\n",
    "    FROM\n",
    "     `{work_project_id}.{cdm_subset_dataset_id}.{table_id}`\n",
    "    \"\"\".format_map({'work_project_id': work_project_id,\n",
    "                    'cdm_subset_dataset_id': cdm_subset_dataset_id,\n",
    "                    'table_id': table_id})\n",
    "    \n",
    "    client.query(sql).to_dataframe(dtypes=schema,\n",
    "                                   progress_bar_type='tqdm').to_csv(path_or_buf=file_name,\n",
    "                                                                    index=False,\n",
    "                                                                    sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
